\startprefacepage

Объем информации в интернете в последнее время очень быстро растет: на данный момент число сайтов исчисляется исчисляется десятками миллиардов, а число веб-страниц --- десятками биллионов. Кроме того, информация в интернете быстро изменяется, веб-страницы обновляются все чаще.  В связи с данными особенностями развития интернета поиск необходимой информации является очень сложной задачей для пользователя, для упрощения которой были созданы поисковые системы. 

Поисковый робот является частью поисковой системы, необходимой для ее корректного функционирования. Его задачей является перебор страниц интернета с целью их загрузки и сохранения в базу данных системы для последующих выдач в пользовательских поисковых запросах. Чтобы удовлетворять требованиям пользователей, поисковая система должна хранить важные веб-страницы, то есть востребованные пользователями. Для чего необходима стратегия приоритезации поискового робота, которая представляет собой комбинацию двух стратегий: отбора веб-страниц и повторного скачивания.

Для определения важности страниц необходим алгоритм ранжирования. Существует два основных подхода к ранжированию веб-страниц. Первый подход основан на анализе веб-графа. Среди алгоритмов, использующих данный подход, алгоритм PageRank, который успешно применяет поисковая система Google, а также HITS. Вычисление подобных рангов является достаточно ресурсоемкой операцией. Второй подход основан на анализе текстовых особенностей веб-страницы, особенностей ее URL-адреса и анализе ее содержимого. К алгоритмам, использующим данный подход относят Okapi BM25, Tf–idf, обучение ранжированию.

Задача стратегии отбора состоит в том, чтобы поисковый робот выбирал важные веб-страницы для скачивания в первую очередь, для чего необходима эвристическая оценка важности. Исходя из метода получения такой оценки, стратегии разделяют на три категории: использующие информацию о текущем обходе (обход в ширину, OPIC, FICA и т.д.), использующие информацию из предыдущих обходов и располагающие полной информацией.

Кроме того, поисковая система должна располагать актуальной информацией о состоянии веб-страниц, для чего поисковый робот должен повторно скачивать страницы, уже имеющиеся в базе поисковой системы. Здесь возникает вопрос: как часто повторно скачивать веб-страницы, и в каком порядке. Для чего необходима стратегия повторного скачивания.

В данной работе описывается разработка стратегии приоритезации поискового робота, базирующейся на методике обучения ранжированию с использованием статических особенностей URL-адресов веб-страниц.

% vim:filetype=tex: