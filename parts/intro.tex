\startprefacepage

Объем информации в интернете в последнее время очень быстро растет. На данный момент число сайтов исчисляется исчисляется десятками миллиардов, а число веб-страниц --- десятками биллионов. Кроме того, информация в интернете быстро изменяется, веб-страницы обновляются все чаще. 

В связи с данными особенностями развития интернета поиск необходимой информации является очень сложной задачей для пользователя. Для упрощения этой задачи были созданы поисковые системы. 

Поисковый робот является частью поисковой системы, необходимой для ее корректного функционирования. Его задачей является перебор страниц интернета. Загруженные роботом страницы сохраняются в базу данных поисковой системы для последующих выдач в пользовательских поисковых запросах.

Чтобы удовлетворять требованиям пользователей, в поисковая система должна хранить в своей базе веб-страницы, которые будут востребованы пользователями поисковой системы. Для этого необходима стратегия отбора веб-страниц, которые поисковый робот должен скачать, и в каком порядке. Для чего необходим алгоритм ранжирования веб-страниц, который будет определять важность веб-страницы. Существует два основных подхода к ранжированию веб-страниц. Первый подход основан на анализе веб-графа. Второй --- на анализе текстовых особенностей веб-страницы, особенностей ее URL-адреса и анализе ее содержимого. 

На основе анализа веб-графа построен алгоритм приоритезации PageRank, который успешно использует поисковая система Google. Но вычисление подобного ранга для каждой страницы является очень ресурсоемкой операцией, поскольку для этого необходимо использовать информацию о всем веб-графе, размер которого велик. 

На базе графовых алгоритмах ранжирования построен ряд стратегий отбора веб-страниц. Например, OPIC \cite{OPIC}, который также является аппроксимацией вычисления PageRank. Также были разработаны алгоритмы, использующие в основе приоритезации информацию о расстоянии между страницами в веб-графе, например, FICA \cite{FICA}. 

На основе анализа статических факторов страницы был разработан алгоритм ранжирования веб-страниц FRank, описанный в работе \cite{FRank}. Но вопрос его применения к приоритезации поискового робота остается открытым, поскольку оценка важности страницы требует информации не только о URL-адресе веб-страницы, но и об ее содержимом.

Кроме того, поисковая система должна располагать актуальной информацией о состоянии веб-страниц. Для чего поисковый робот должен повторно скачивать веб-страницы, уже имеющиеся в базе поисковой системы. Здесь возникает вопрос: как часто повторно скачивать веб-страницы, и в каком порядке. Для чего необходима стратегия повторного скачивания.

Алгоритм приоритезации поискового робота представляет собой комбинацию двух стратегий: отбора веб-страниц и повторного скачивания.

В данной работе описывается разработка программы, реализующей поискового робота. Для алгоритма приоритезации кототого примененяется как анализ веб-графа, так и анализ текстовых особенностей URL-адресов веб-страниц.

% vim:filetype=tex: